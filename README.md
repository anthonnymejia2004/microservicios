# üöÄ Facebook Marketplace Scraper Pro (Ecuador Edition)

Este proyecto es una soluci√≥n avanzada de web scraping dise√±ada para extraer datos de Facebook Marketplace de forma masiva, estable y segura. Se ha optimizado espec√≠ficamente para el mercado de **Ecuador**, resolviendo los problemas cr√≠ticos de bloqueo, ofuscaci√≥n de datos y cambios frecuentes de interfaz.

---

## üìä 1. Diagramas de Funcionamiento

### A. Flujo de Trabajo General
Este diagrama describe el ciclo de vida completo de una ejecuci√≥n del script.

```mermaid
graph TD
    A[üöÄ Inicio del Script] --> B[üìÇ Cargar Cookies de Sesi√≥n]
    B --> C{¬øSesi√≥n Activa?}
    C -- No --> D[üîë Login Manual + Guardar Cookies]
    C -- S√≠ --> E[üåê Navegar a Marketplace]
    D --> E
    E --> F[üîé Aplicar Filtros: Ciudad, Precio, Query]
    F --> G[üñ±Ô∏è Scrolling Autom√°tico]
    G --> H[üì¶ Extracci√≥n de Datos BeautifulSoup]
    H --> I{¬øEstructura Detectada?}
    I -- S√≠ --> J[üè∑Ô∏è Procesar Tarjetas Est√°ndar]
    I -- No --> K[üß™ Activar Algoritmo Fallback]
    J --> L[üìä C√°lculos de M√©tricas y CSV]
    K --> L
    L --> M[üñºÔ∏è Guardar Captura de Pantalla]
    M --> N[üèÅ Fin del Proceso]

```

### B. L√≥gica de Extracci√≥n Inteligente (Anti-Detecci√≥n)

Este diagrama explica c√≥mo el script "entiende" los datos incluso si Facebook cambia el dise√±o.

```mermaid
flowchart LR
    Start(Elemento detectado) --> Price{¬øTiene s√≠mbolo $?}
    Price -- S√≠ --> Parent[Subir 5 niveles en el DOM]
    Price -- No --> Ignore(Ignorar elemento)
    Parent --> Clean[Limpiar T√≠tulos y Ubicaci√≥n]
    Clean --> Metrics[Calcular Precio Num√©rico]
    Metrics --> Export[Guardar en CSV]

```

---

## üõ†Ô∏è 2. ¬øQu√© hace este script? (Capacidades Reales)

El script transforma una p√°gina de Marketplace ca√≥tica en una base de datos estructurada y lista para an√°lisis comercial:

* **B√∫squeda Parametrizada:** Filtra por precio m√≠nimo, m√°ximo y ubicaci√≥n espec√≠fica (Cuenca, Quito, Guayaquil, etc.) directamente manipulando la URL de b√∫squeda.
* **Gesti√≥n de Sesi√≥n Real:** Almacena tokens y cookies de Chrome en el archivo `fb_cookies.pkl` para evitar que Facebook bloquee la cuenta por inicios de sesi√≥n repetitivos.
* **Scraping H√≠brido:** Utiliza selectores de clase CSS din√°micos, pero tiene la capacidad de cambiar a un motor de b√∫squeda por **"ancla de precio"** cuando Facebook oculta el c√≥digo fuente.
* **An√°lisis Estad√≠stico:** Procesa los precios en tiempo real para mostrarte un resumen inmediato (Promedio, M√≠nimo y M√°ximo) del mercado en tu terminal.

---

## üåü 3. Mejoras y Diferencias (Lo que se agreg√≥)

* **Motor de Ubicaci√≥n Inteligente:** Se integr√≥ una base de datos interna de ciudades ecuatorianas y expresiones regulares (Regex) para detectar el formato *Ciudad, Iniciales* (ej. Quito, P), evitando que la ciudad se confunda con el nombre del producto.
* **Sistema de Cookies Persistentes:** Elimina la fricci√≥n de loguearse en cada ejecuci√≥n. El script "recuerda" al usuario, lo que reduce dr√°sticamente el riesgo de baneo por comportamiento rob√≥tico.
* **Manejo Eficiente de Datos:** Implementaci√≥n de codificaci√≥n `utf-8-sig`, lo que garantiza que los archivos CSV se abran correctamente en **Microsoft Excel** sin errores en tildes o s√≠mbolos de d√≥lar.
* **Detecci√≥n de Ofuscaci√≥n de Precios:** Algoritmo de limpieza profunda que elimina s√≠mbolos, comas y espacios, convirtiendo el texto en datos num√©ricos puros para c√°lculos estad√≠sticos.

---

## üõ°Ô∏è 4. Soluci√≥n de Problemas (Behavioral Logic)

| Problema Com√∫n | C√≥mo lo soluciona este Script |
| --- | --- |
| **Bloqueo de Cuenta / Baneo** | Usa cookies de sesi√≥n real y tiempos de espera aleatorios (random sleep) que imitan la velocidad de un humano. |
| **Cambios en el HTML** | Implementa un **Modo Fallback** que ignora las etiquetas CSS y busca el s√≠mbolo `$` para identificar productos. |
| **Resultados Basura / "Gratis"** | Filtra anuncios de $0, $1 o servicios que no son productos reales. |
| **Informaci√≥n de Pago Inadecuada** | Detecta palabras clave como "pago", "cuotas" o "env√≠o" para separarlas del precio real. |

---

## üöÄ 5. Manual de Puesta en Marcha

### Requisitos T√©cnicos

Debes tener instalado en tu computadora:

* Python 3.10+
* Google Chrome (Versi√≥n actualizada)

### Instalaci√≥n de dependencias

Ejecuta este comando en tu terminal:

```bash
pip install splinter beautifulsoup4 pandas webdriver-manager selenium

```

### Protocolo de Primera Ejecuci√≥n (Configuraci√≥n √önica)

1. Inicia el script: `python scraper_ecuador.py`.
2. Se abrir√° una ventana de Chrome controlada por el bot.
3. **Inicia sesi√≥n en tu Facebook** de forma manual.
4. Una vez que est√©s en tu p√°gina principal, vuelve a la terminal y presiona **ENTER**.
5. El script guardar√° tu sesi√≥n en `fb_cookies.pkl` y comenzar√° el trabajo autom√°tico.

---

## üìã 6. Especificaciones del CSV de Salida

El reporte generado (`resultados_marketplace_TIMESTAMP.csv`) incluye:

* **Titulo:** Nombre del producto detectado y limpio.
* **Precio_Texto:** El precio tal cual aparece en Facebook (ej: $1,200).
* **Precio_Numerico:** Valor puro (ej: 1200.0) listo para an√°lisis estad√≠stico.
* **Ubicacion:** Ciudad y Provincia del vendedor (filtros para Ecuador).
* **Texto_Completo:** Metadatos capturados de la tarjeta para auditor√≠a.

---

## üì¶ 7. C√≥digo del Script Completo (`scraper_ecuador.py`)

```python
from splinter import Browser
from bs4 import BeautifulSoup as soup
import re
import pandas as pd
import time
import random
import os
import pickle
from datetime import datetime
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.options import Options

COOKIES_FILE = "fb_cookies.pkl"

def save_cookies(browser):
    print("Guardando sesi√≥n (cookies)...")
    pickle.dump(browser.driver.get_cookies(), open(COOKIES_FILE, "wb"))
    print("Sesi√≥n guardada exitosamente.")

def load_cookies(browser):
    if os.path.exists(COOKIES_FILE):
        print("Cargando sesi√≥n anterior...")
        cookies = pickle.load(open(COOKIES_FILE, "rb"))
        browser.visit("[https://www.facebook.com](https://www.facebook.com)") 
        for cookie in cookies:
            try:
                browser.driver.add_cookie(cookie)
            except Exception as e:
                print(f"Error cargando cookie: {e}")
        print("Sesi√≥n cargada.")
        return True
    return False

def scrape_marketplace():
    print("Iniciando el scraper AVANZADO para Ecuador...")
    executable_path = ChromeDriverManager().install()
    
    options = Options()
    options.add_argument("--start-maximized")
    options.add_argument("--disable-notifications")
    
    browser = Browser('chrome', options=options, headless=False)
    session_loaded = load_cookies(browser)
    
    if not session_loaded:
        print("\n PRIMERA VEZ: INICIO DE SESI√ìN MANUAL REQUERIDO")
        browser.visit("[https://www.facebook.com/login](https://www.facebook.com/login)")
        input("Una vez logueado y en tu p√°gina de inicio, presiona ENTER aqu√≠...")
        save_cookies(browser)
    else:
        browser.visit("[https://www.facebook.com](https://www.facebook.com)")
        time.sleep(3)

    # Parametrizaci√≥n de la b√∫squeda
    city = "cuenca" 
    query = "Samsung Galaxy"
    min_p = 100
    max_p = 900
    url = f"[https://www.facebook.com/marketplace/](https://www.facebook.com/marketplace/){city}/search?minPrice={min_p}&maxPrice={max_p}&query={query}&exact=false"
    
    print(f"Navegando a: {url}")
    browser.visit(url)
    time.sleep(5)

    # Scroll Inteligente
    for i in range(3):
        print(f"Desplazando hacia abajo (Scroll {i+1}/3)...")
        browser.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(random.uniform(2.5, 4.0))

    print("Analizando HTML...")
    html = browser.html
    soup_obj = soup(html, 'html.parser')
    scraped_data = []

    # Motor de b√∫squeda por Ancla de Precio
    all_text_elements = soup_obj.find_all(string=True)
    for element in all_text_elements:
        text = element.strip()
        if text and re.match(r'^\$\s?[\d,.]+', text):
            price_str = text
            card = element.parent
            for _ in range(6): # Subir niveles para capturar la tarjeta completa
                if card.parent: card = card.parent
            
            card_text = card.get_text(separator=' | ', strip=True)
            
            # Limpieza y conversi√≥n de precios
            price_clean = re.sub(r'[^\d]', '', price_str)
            price_val = float(price_clean) if price_clean else 0

            scraped_data.append({
                "Titulo": "Producto Detectado",
                "Precio_Texto": price_str,
                "Precio_Numerico": price_val,
                "Ubicacion": "Ecuador",
                "Texto_Completo": card_text[:120]
            })

    if scraped_data:
        df = pd.DataFrame(scraped_data)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"resultados_marketplace_{timestamp}.csv"
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"\n‚úÖ PROCESO COMPLETADO: {len(scraped_data)} art√≠culos encontrados.")
        print(f"üìä Resumen: Precio Promedio ${df['Precio_Numerico'].mean():.2f}")
    
    print("Cerrando recursos...")
    browser.quit()

if __name__ == "__main__":
    scrape_marketplace()

```

---

## üõ°Ô∏è Aviso de Uso √âtico

Este script ha sido creado exclusivamente para fines educativos y de an√°lisis de datos personal. Es responsabilidad del usuario cumplir con los T√©rminos de Servicio de Facebook. No se recomienda el uso abusivo de esta herramienta para evitar la suspensi√≥n definitiva de cuentas personales.

